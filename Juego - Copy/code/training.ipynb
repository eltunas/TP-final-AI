{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from AlgoritmoGenetico import GeneticAlgorithm\n",
    "import os\n",
    "import pygame\n",
    "from main import Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros del algoritmo genético\n",
    "population_size = 30\n",
    "mutation_rate = 0.01\n",
    "num_generations = 300\n",
    "input_size = 12  # Tamaño del vector de estado\n",
    "output_size = 4  # Cuatro acciones posibles: izquierda, derecha, disparar, nada\n",
    "\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"  # Configurar el driver de video en \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando la red neuronal mediante algoritmo genético...\n",
      "Inciando generacion 0\n",
      "Agente 0 Iniciado. Level: 2\n",
      "Agente 1 Iniciado. Level: 2\n",
      "Agente 2 Iniciado. Level: 2\n",
      "Agente 3 Iniciado. Level: 2\n",
      "Agente 4 Iniciado. Level: 2\n",
      "Agente 5 Iniciado. Level: 2\n",
      "Agente 6 Iniciado. Level: 2\n",
      "Agente 7 Iniciado. Level: 2\n",
      "Agente 8 Iniciado. Level: 2\n",
      "Agente 9 Iniciado. Level: 2\n",
      "Agente 10 Iniciado. Level: 2\n",
      "Agente 11 Iniciado. Level: 2\n",
      "Agente 12 Iniciado. Level: 2\n",
      "Agente 13 Iniciado. Level: 2\n",
      "Agente 14 Iniciado. Level: 2\n",
      "Agente 15 Iniciado. Level: 2\n",
      "Agente 16 Iniciado. Level: 2\n",
      "Agente 17 Iniciado. Level: 2\n",
      "Agente 18 Iniciado. Level: 2\n",
      "Agente 19 Iniciado. Level: 2\n",
      "Agente 20 Iniciado. Level: 2\n",
      "Agente 21 Iniciado. Level: 2\n",
      "Agente 22 Iniciado. Level: 2\n",
      "Agente 23 Iniciado. Level: 2\n",
      "Agente 24 Iniciado. Level: 2\n",
      "Agente 25 Iniciado. Level: 2\n",
      "Agente 26 Iniciado. Level: 2\n",
      "Agente 27 Iniciado. Level: 2\n",
      "Agente 28 Iniciado. Level: 2\n",
      "Agente 29 Iniciado. Level: 2\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021ED37082C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021ED1F916C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "-1 Vida. Te quedan 2\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje800, Fitness: -1400\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje700, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Scores de la generación 0: [-800, -700, -800, -700, -600, -700, -1400, -600, -700, -500, -700, -500, -700, -700, -800, -700, -400, -800, -700, -500, -800, -400, -800, -500, -500, -600, -700, -800, -600, -500]\n",
      "Generación 0: Mejor puntaje = -400\n",
      "Inciando generacion 1\n",
      "Agente 0 Iniciado. Level: 2\n",
      "Agente 1 Iniciado. Level: 2\n",
      "Agente 2 Iniciado. Level: 2\n",
      "Agente 3 Iniciado. Level: 2\n",
      "Agente 4 Iniciado. Level: 2\n",
      "Agente 5 Iniciado. Level: 2\n",
      "Agente 6 Iniciado. Level: 2\n",
      "Agente 7 Iniciado. Level: 2\n",
      "Agente 8 Iniciado. Level: 2\n",
      "Agente 9 Iniciado. Level: 2\n",
      "Agente 10 Iniciado. Level: 2\n",
      "Agente 11 Iniciado. Level: 2\n",
      "Agente 12 Iniciado. Level: 2\n",
      "Agente 13 Iniciado. Level: 2\n",
      "Agente 14 Iniciado. Level: 2\n",
      "Agente 15 Iniciado. Level: 2\n",
      "Agente 16 Iniciado. Level: 2\n",
      "Agente 17 Iniciado. Level: 2\n",
      "Agente 18 Iniciado. Level: 2\n",
      "Agente 19 Iniciado. Level: 2\n",
      "Agente 20 Iniciado. Level: 2\n",
      "Agente 21 Iniciado. Level: 2\n",
      "Agente 22 Iniciado. Level: 2\n",
      "Agente 23 Iniciado. Level: 2\n",
      "Agente 24 Iniciado. Level: 2\n",
      "Agente 25 Iniciado. Level: 2\n",
      "Agente 26 Iniciado. Level: 2\n",
      "Agente 27 Iniciado. Level: 2\n",
      "Agente 28 Iniciado. Level: 2\n",
      "Agente 29 Iniciado. Level: 2\n",
      "-1 Vida. Te quedan 2\n",
      "-1 Vida. Te quedan 2\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -1700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -1600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Scores de la generación 1: [-700, -400, -400, -800, -800, -700, -1700, -600, -1600, -500, -600, -700, -700, -800, -400, -700, -800, -600, -700, -800, -600, -500, -400, -800, -700, -600, -600, -600, -600, -700]\n",
      "Generación 1: Mejor puntaje = -400\n",
      "Inciando generacion 2\n",
      "Agente 0 Iniciado. Level: 2\n",
      "Agente 1 Iniciado. Level: 2\n",
      "Agente 2 Iniciado. Level: 2\n",
      "Agente 3 Iniciado. Level: 2\n",
      "Agente 4 Iniciado. Level: 2\n",
      "Agente 5 Iniciado. Level: 2\n",
      "Agente 6 Iniciado. Level: 2\n",
      "Agente 7 Iniciado. Level: 2\n",
      "Agente 8 Iniciado. Level: 2\n",
      "Agente 9 Iniciado. Level: 2\n",
      "Agente 10 Iniciado. Level: 2\n",
      "Agente 11 Iniciado. Level: 2\n",
      "Agente 12 Iniciado. Level: 2\n",
      "Agente 13 Iniciado. Level: 2\n",
      "Agente 14 Iniciado. Level: 2\n",
      "Agente 15 Iniciado. Level: 2\n",
      "Agente 16 Iniciado. Level: 2\n",
      "Agente 17 Iniciado. Level: 2\n",
      "Agente 18 Iniciado. Level: 2\n",
      "Agente 19 Iniciado. Level: 2\n",
      "Agente 20 Iniciado. Level: 2\n",
      "Agente 21 Iniciado. Level: 2\n",
      "Agente 22 Iniciado. Level: 2\n",
      "Agente 23 Iniciado. Level: 2\n",
      "Agente 24 Iniciado. Level: 2\n",
      "Agente 25 Iniciado. Level: 2\n",
      "Agente 26 Iniciado. Level: 2\n",
      "Agente 27 Iniciado. Level: 2\n",
      "Agente 28 Iniciado. Level: 2\n",
      "Agente 29 Iniciado. Level: 2\n",
      "-1 Vida. Te quedan 2\n",
      "-1 Vida. Te quedan 2\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -1600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -1700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Scores de la generación 2: [-400, -700, -500, -400, -700, -600, -600, -400, -400, -500, -700, -400, -800, -700, -600, -700, -500, -700, -500, -700, -400, -1600, -1700, -700, -600, -600, -500, -500, -600, -600]\n",
      "Generación 2: Mejor puntaje = -400\n",
      "Inciando generacion 3\n",
      "Agente 0 Iniciado. Level: 2\n",
      "Agente 1 Iniciado. Level: 2\n",
      "Agente 2 Iniciado. Level: 2\n",
      "Agente 3 Iniciado. Level: 2\n",
      "Agente 4 Iniciado. Level: 2\n",
      "Agente 5 Iniciado. Level: 2\n",
      "Agente 6 Iniciado. Level: 2\n",
      "Agente 7 Iniciado. Level: 2\n",
      "Agente 8 Iniciado. Level: 2\n",
      "Agente 9 Iniciado. Level: 2\n",
      "Agente 10 Iniciado. Level: 2\n",
      "Agente 11 Iniciado. Level: 2\n",
      "Agente 12 Iniciado. Level: 2\n",
      "Agente 13 Iniciado. Level: 2\n",
      "Agente 14 Iniciado. Level: 2\n",
      "Agente 15 Iniciado. Level: 2\n",
      "Agente 16 Iniciado. Level: 2\n",
      "Agente 17 Iniciado. Level: 2\n",
      "Agente 18 Iniciado. Level: 2\n",
      "Agente 19 Iniciado. Level: 2\n",
      "Agente 20 Iniciado. Level: 2\n",
      "Agente 21 Iniciado. Level: 2\n",
      "Agente 22 Iniciado. Level: 2\n",
      "Agente 23 Iniciado. Level: 2\n",
      "Agente 24 Iniciado. Level: 2\n",
      "Agente 25 Iniciado. Level: 2\n",
      "Agente 26 Iniciado. Level: 2\n",
      "Agente 27 Iniciado. Level: 2\n",
      "Agente 28 Iniciado. Level: 2\n",
      "Agente 29 Iniciado. Level: 2\n",
      "-1 Vida. Te quedan 2\n",
      "-1 Vida. Te quedan 2\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -1400\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje700, Fitness: -300\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -1500\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje200, Fitness: -800\n",
      "Time Finished\n",
      "Puntaje700, Fitness: -300\n",
      "Time Finished\n",
      "Puntaje700, Fitness: -300\n",
      "Time Finished\n",
      "Puntaje700, Fitness: -300\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Scores de la generación 3: [-500, -600, -600, -400, -400, -600, -400, -700, -600, -400, -1400, -600, -500, -300, -700, -400, -1500, -400, -700, -800, -600, -600, -600, -600, -800, -300, -300, -300, -700, -500]\n",
      "Generación 3: Mejor puntaje = -300\n",
      "Inciando generacion 4\n",
      "Agente 0 Iniciado. Level: 2\n",
      "Agente 1 Iniciado. Level: 2\n",
      "Agente 2 Iniciado. Level: 2\n",
      "Agente 3 Iniciado. Level: 2\n",
      "Agente 4 Iniciado. Level: 2\n",
      "Agente 5 Iniciado. Level: 2\n",
      "Agente 6 Iniciado. Level: 2\n",
      "Agente 7 Iniciado. Level: 2\n",
      "Agente 8 Iniciado. Level: 2\n",
      "Agente 9 Iniciado. Level: 2\n",
      "Agente 10 Iniciado. Level: 2\n",
      "Agente 11 Iniciado. Level: 2\n",
      "Agente 12 Iniciado. Level: 2\n",
      "Agente 13 Iniciado. Level: 2\n",
      "Agente 14 Iniciado. Level: 2\n",
      "Agente 15 Iniciado. Level: 2\n",
      "Agente 16 Iniciado. Level: 2\n",
      "Agente 17 Iniciado. Level: 2\n",
      "Agente 18 Iniciado. Level: 2\n",
      "Agente 19 Iniciado. Level: 2\n",
      "Agente 20 Iniciado. Level: 2\n",
      "Agente 21 Iniciado. Level: 2\n",
      "Agente 22 Iniciado. Level: 2\n",
      "Agente 23 Iniciado. Level: 2\n",
      "Agente 24 Iniciado. Level: 2\n",
      "Agente 25 Iniciado. Level: 2\n",
      "Agente 26 Iniciado. Level: 2\n",
      "Agente 27 Iniciado. Level: 2\n",
      "Agente 28 Iniciado. Level: 2\n",
      "Agente 29 Iniciado. Level: 2\n",
      "-1 Vida. Te quedan 2\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -1500\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje500, Fitness: -500\n",
      "Time Finished\n",
      "Puntaje100, Fitness: -900\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje600, Fitness: -400\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje400, Fitness: -600\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Time Finished\n",
      "Puntaje300, Fitness: -700\n",
      "Scores de la generación 4: [-700, -500, -700, -600, -600, -700, -700, -500, -400, -700, -700, -700, -700, -1500, -500, -500, -700, -600, -600, -600, -600, -500, -900, -600, -400, -600, -700, -600, -700, -700]\n",
      "Generación 4: Mejor puntaje = -400\n",
      "Inciando generacion 5\n",
      "Agente 0 Iniciado. Level: 2\n",
      "Agente 1 Iniciado. Level: 2\n",
      "Agente 2 Iniciado. Level: 2\n",
      "Agente 3 Iniciado. Level: 2\n",
      "Agente 4 Iniciado. Level: 2\n",
      "Agente 5 Iniciado. Level: 2\n",
      "Agente 6 Iniciado. Level: 2\n",
      "Agente 7 Iniciado. Level: 2\n",
      "Agente 8 Iniciado. Level: 2\n",
      "Agente 9 Iniciado. Level: 2\n",
      "Agente 10 Iniciado. Level: 2\n",
      "Agente 11 Iniciado. Level: 2\n",
      "Agente 12 Iniciado. Level: 2\n",
      "Agente 13 Iniciado. Level: 2\n",
      "Agente 14 Iniciado. Level: 2\n",
      "Agente 15 Iniciado. Level: 2\n",
      "Agente 16 Iniciado. Level: 2\n",
      "Agente 17 Iniciado. Level: 2\n",
      "Agente 18 Iniciado. Level: 2\n",
      "Agente 19 Iniciado. Level: 2\n",
      "Agente 20 Iniciado. Level: 2\n",
      "Agente 21 Iniciado. Level: 2\n",
      "Agente 22 Iniciado. Level: 2\n",
      "Agente 23 Iniciado. Level: 2\n",
      "Agente 24 Iniciado. Level: 2\n",
      "Agente 25 Iniciado. Level: 2\n",
      "Agente 26 Iniciado. Level: 2\n",
      "Agente 27 Iniciado. Level: 2\n",
      "Agente 28 Iniciado. Level: 2\n",
      "Agente 29 Iniciado. Level: 2\n"
     ]
    }
   ],
   "source": [
    "pygame.init()  # Asegúrate de inicializar Pygame\n",
    "pygame.font.init()\n",
    "\n",
    "\n",
    "gen_algo = GeneticAlgorithm(population_size, mutation_rate, num_generations, input_size, output_size)\n",
    "\n",
    "print(\"Entrenando la red neuronal mediante algoritmo genético...\")\n",
    "trained_model = gen_algo.evolve()  # Este será el mejor modelo entrenado\n",
    "\n",
    "trained_model.save(\"resultado_1.keras\")\n",
    "\n",
    "scores = gen_algo.best_scores\n",
    "rewards =  gen_algo.best_total_scores\n",
    "epsilons = gen_algo.best_epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "class GeneticAlgorithm:\n",
    "    def __init__(self, population_size, mutation_rate, num_generations, input_size, output_size, game):\n",
    "        self.population_size = population_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.num_generations = num_generations\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.game = game  # La instancia del juego para evaluar cada red\n",
    "        self.population = self.initialize_population()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Construye un modelo de red neuronal.\"\"\"\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu', input_shape=(self.input_size,)),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(self.output_size, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def initialize_population(self):\n",
    "        \"\"\"Inicializa una población de redes con pesos aleatorios.\"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            model = self.build_model()\n",
    "            weights = [layer.get_weights() for layer in model.layers]\n",
    "            population.append(weights)\n",
    "        return population\n",
    "\n",
    "    def evaluate_fitness(self, weights, instance_id, render=True):\n",
    "        \"\"\"Evalúa la aptitud de una red neuronal ejecutándola en el juego.\"\"\"\n",
    "        from main import Game\n",
    "        game_instance = Game(800, 600, render=render)  # Cada agente tiene su propia instancia de Game\n",
    "\n",
    "        print(f'Agente {instance_id} Iniciado')\n",
    "        \n",
    "        # Configura el modelo con los pesos dados\n",
    "        model = self.build_model()\n",
    "        for layer, weight in zip(model.layers, weights):\n",
    "            layer.set_weights(weight)\n",
    "\n",
    "        total_score = 0\n",
    "        game_instance.reset()\n",
    "        clock = pygame.time.Clock()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Lógica del juego y predicción de acción\n",
    "            game_state = game_instance.get_game_state()\n",
    "            input_data = self.preprocess_game_state(game_state).reshape(1, -1)\n",
    "            action = np.argmax(model.predict(input_data))\n",
    "            \n",
    "            _, reward, done = game_instance.step(action)\n",
    "            total_score += reward\n",
    "\n",
    "            if(reward != 0):\n",
    "                print(f'Agente {instance_id} Jugo {action} y consiguio una recompensa de {reward}')\n",
    "            if(action ==3):\n",
    "                print(f'Agente {instance_id} disparo')\n",
    "            \n",
    "            game_instance.run()  # Solo ejecuta run si render está activado\n",
    "\n",
    "            clock.tick(120)  # Controla la velocidad del bucle\n",
    "\n",
    "        return total_score\n",
    "\n",
    "    def preprocess_game_state(self, game_state):\n",
    "        \"\"\"Preprocesa el estado del juego para convertirlo en una entrada válida para el modelo.\"\"\"\n",
    "        player_pos = np.array(game_state['player_position'])\n",
    "        alien_pos, alien_distance = game_state['closest_alien']\n",
    "        laser_pos, laser_distance = game_state['closest_alien_laser']\n",
    "        obstacle_pos, obstacle_distance = game_state['closest_obstacle']\n",
    "        \n",
    "        alien_pos = np.array(alien_pos) if alien_pos else np.zeros(2)\n",
    "        laser_pos = np.array(laser_pos) if laser_pos else np.zeros(2)\n",
    "        obstacle_pos = np.array(obstacle_pos) if obstacle_pos else np.zeros(2)\n",
    "        \n",
    "        input_data = np.concatenate([player_pos, alien_pos, [alien_distance], laser_pos, [laser_distance], obstacle_pos, [obstacle_distance]])\n",
    "        return input_data\n",
    "\n",
    "    def select_best_individuals(self, fitness_scores, num_best=2):\n",
    "        \"\"\"Selecciona los mejores individuos basándose en sus puntajes de aptitud.\"\"\"\n",
    "        best_indices = np.argsort(fitness_scores)[-num_best:]\n",
    "        return [self.population[i] for i in best_indices]\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        \"\"\"Realiza cruce entre dos individuos para producir un nuevo conjunto de pesos.\"\"\"\n",
    "        child = []\n",
    "        for p1_layer, p2_layer in zip(parent1, parent2):\n",
    "            new_weights = [(p1 + p2) / 2 for p1, p2 in zip(p1_layer, p2_layer)]\n",
    "            child.append(new_weights)\n",
    "        return child\n",
    "\n",
    "    def mutate(self, weights):\n",
    "        \"\"\"Aplica mutación aleatoria a un conjunto de pesos.\"\"\"\n",
    "        for layer in weights:\n",
    "            for i in range(len(layer)):\n",
    "                if np.random.rand() < self.mutation_rate:\n",
    "                    layer[i] += np.random.normal()\n",
    "        return weights\n",
    "\n",
    "    def create_new_generation(self, best_individuals):\n",
    "        \"\"\"Crea una nueva generación usando los mejores individuos y aplicando cruce y mutación.\"\"\"\n",
    "        new_population = []\n",
    "        while len(new_population) < self.population_size:\n",
    "            parent1, parent2 = random.sample(best_individuals, 2)\n",
    "            child = self.crossover(parent1, parent2)\n",
    "            child = self.mutate(child)\n",
    "            new_population.append(child)\n",
    "        return new_population\n",
    "\n",
    "    def evolve(self):\n",
    "        \"\"\"Ejecuta el ciclo de evolución a través de varias generaciones.\"\"\"\n",
    "        for generation in range(self.num_generations):\n",
    "            print(f'Inciando generacion {generation}')\n",
    "\n",
    "            fitness_scores = []\n",
    "\n",
    "            # Evaluar el primer agente con renderizado activado\n",
    "            #fitness_score = self.evaluate_fitness(self.population[0], instance_id=0, render=True)\n",
    "            #fitness_scores.append(fitness_score)\n",
    "\n",
    "            # Evaluar el resto de los agentes sin renderizado\n",
    "            with ThreadPoolExecutor(max_workers=self.population_size) as executor:\n",
    "                args = [(self.population[i], i, False) for i in range(0, self.population_size)]\n",
    "                other_fitness_scores = list(executor.map(lambda arg: self.evaluate_fitness(*arg), args))\n",
    "                fitness_scores.extend(other_fitness_scores)\n",
    "\n",
    "            print(f'Socres de la generacion {generation}: {fitness_scores}')\n",
    "            # Seleccionar los mejores individuos y generar la nueva población\n",
    "            best_individuals = self.select_best_individuals(fitness_scores, num_best=5)\n",
    "            self.population = self.create_new_generation(best_individuals)\n",
    "\n",
    "            print(f\"Generación {generation}: Mejor puntaje = {max(fitness_scores)}\")\n",
    "\n",
    "        # Obtener el mejor modelo entrenado\n",
    "        best_weights = self.select_best_individuals(fitness_scores, num_best=1)[0]\n",
    "        final_model = self.build_model()\n",
    "        for layer, weight in zip(final_model.layers, best_weights):\n",
    "            layer.set_weights(weight)\n",
    "\n",
    "        return final_model\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "    def __init__(self, population_size, mutation_rate, num_generations, input_size, output_size):\n",
    "        self.population_size = population_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.num_generations = num_generations\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.population = self.initialize_population()\n",
    "        self.level = 1\n",
    "        self.win_count = 0\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Construye un modelo de red neuronal.\"\"\"\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='relu', input_shape=(self.input_size,)),\n",
    "            tf.keras.layers.Dense(32, activation='relu'),\n",
    "            tf.keras.layers.Dense(self.output_size, activation='softmax')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def initialize_population(self):\n",
    "        \"\"\"Inicializa una población de redes con pesos aleatorios.\"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            model = self.build_model()\n",
    "            weights = [layer.get_weights() for layer in model.layers]\n",
    "            population.append(weights)\n",
    "        return population\n",
    "\n",
    "    def evaluate_fitness(self,  weights, generation, instance_id):\n",
    "        \"\"\"Evalúa la aptitud de una red neuronal ejecutándola en el juego.\"\"\"\n",
    "\n",
    "        print(f'Agente {instance_id} Iniciado. Level: {self.level}')\n",
    "        \n",
    "        game = Game(800, 600)\n",
    "\n",
    "        model = self.build_model()\n",
    "        for layer, weight in zip(model.layers, weights):\n",
    "            layer.set_weights(weight)\n",
    "        \n",
    "        total_score = 0\n",
    "        game.reset()  # Reinicia el juego\n",
    "        clock = pygame.time.Clock()\n",
    "        done = False\n",
    "\n",
    "        if self.level == 1:\n",
    "            shoot = False\n",
    "            shoot_speed = 0\n",
    "            time_limit= 60\n",
    "\n",
    "            if generation > 15:\n",
    "                time_limit = 120\n",
    "\n",
    "            elif generation > 10:\n",
    "                time_limit = 90\n",
    "        \n",
    "        elif self.level == 2:\n",
    "            shoot = True\n",
    "            shoot_speed = 600\n",
    "            time_limit = 120\n",
    "\n",
    "        elif self.level == 3:\n",
    "            shoot = True\n",
    "            shoot_speed = 300\n",
    "            time_limit = 180\n",
    "\n",
    "        \"\"\"\n",
    "        if generation > 0:\n",
    "            shoot = True\n",
    "        else:\n",
    "            shoot = False\n",
    "        \n",
    "        if generation > 15:\n",
    "            shoot_speed = 200\n",
    "        elif generation > 10:\n",
    "            shoot_speed = 400\n",
    "        else:\n",
    "            shoot_speed= 600\n",
    "\n",
    "\n",
    "        start_time = time.time()  # Iniciar el temporizador\n",
    "\n",
    "        if generation > 10:\n",
    "            time_limit = 180\n",
    "        elif generation > 5:\n",
    "            time_limit = 120\n",
    "        elif generation > 2:\n",
    "            time_limit = 60\n",
    "        else:\n",
    "            time_limit = 30\n",
    "        \"\"\"\n",
    "\n",
    "        start_time = time.time()  # Iniciar el temporizador\n",
    "\n",
    "        pygame.font.init()\n",
    "        font = pygame.font.Font(None, 36)  # Fuente predeterminada, tamaño 36\n",
    "\n",
    "        ALIENLASER = pygame.USEREVENT + 1\n",
    "        pygame.time.set_timer(ALIENLASER, shoot_speed)\n",
    "\n",
    "        while not done:\n",
    "            elapsed_time = int(time.time() - start_time)\n",
    "\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "\n",
    "                if event.type == ALIENLASER and shoot == True:\n",
    "                    game.alien_shoot()\n",
    "\n",
    "            game_state = game.get_game_state()\n",
    "            input_data = self.preprocess_game_state(game_state).reshape(1, -1)\n",
    "\n",
    "            epsilon = 0.1  # Probabilidad de explorar aleatoriamente\n",
    "\n",
    "            # Obtener las probabilidades de las acciones\n",
    "            action_probs = model.predict(input_data, verbose=0)\n",
    "            print(action_probs)\n",
    "\n",
    "            # Decidir si explorar o explotar\n",
    "            if np.random.rand() < epsilon:\n",
    "                # Exploración: elegir una acción aleatoria\n",
    "                action = np.random.choice(len(action_probs))\n",
    "            else:\n",
    "                # Explotación: elegir la acción con la mayor probabilidad\n",
    "                action = np.argmax(action_probs) \n",
    "\n",
    "            _, reward, done = game.step(action, start_time)\n",
    "            total_score += reward\n",
    "\n",
    "            game.screen.fill((30, 30, 30))\n",
    "            game.run()\n",
    "\n",
    "            timer_text = font.render(f\"Tiempo: {elapsed_time}s\", True, (255, 255, 255))\n",
    "            text_rect = timer_text.get_rect(center=(game.screen.get_width() // 2, 20))\n",
    "            game.screen.blit(timer_text, text_rect)\n",
    "\n",
    "            pygame.display.flip()\n",
    "            clock.tick(120)\n",
    "\n",
    "            if elapsed_time > time_limit:\n",
    "                print(\"Time Finished\")\n",
    "                done = True\n",
    "                total_score -= 1000\n",
    "            \n",
    "            if not game.aliens.sprites():\n",
    "                print(\"Ganaste\")\n",
    "                self.win_count += 1\n",
    "                if self.win_count >= 5 and self.level != 3:\n",
    "                    self.level += 1\n",
    "                    self.win_count = 0\n",
    "                done = True\n",
    "\n",
    "        print(total_score)\n",
    "        return total_score\n",
    "\n",
    "    def preprocess_game_state(self, game_state):\n",
    "        \"\"\"Preprocesa el estado del juego para convertirlo en una entrada válida para el modelo.\"\"\"\n",
    "        player_pos = np.array(game_state['player_position'])\n",
    "        alien_pos, alien_distance = game_state['closest_alien']\n",
    "        laser_pos, laser_distance = game_state['closest_alien_laser']\n",
    "        obstacle_pos, obstacle_distance = game_state['closest_obstacle']\n",
    "        \n",
    "        alien_pos = np.array(alien_pos) if alien_pos else np.zeros(2)\n",
    "        laser_pos = np.array(laser_pos) if laser_pos else np.zeros(2)\n",
    "        obstacle_pos = np.array(obstacle_pos) if obstacle_pos else np.zeros(2)\n",
    "        \n",
    "        input_data = np.concatenate([player_pos, alien_pos, [alien_distance], laser_pos, [laser_distance], obstacle_pos, [obstacle_distance]])\n",
    "        return input_data\n",
    "\n",
    "    def select_best_individuals(self, fitness_scores, num_best=2):\n",
    "        \"\"\"Selecciona los mejores individuos basándose en sus puntajes de aptitud.\"\"\"\n",
    "        best_indices = np.argsort(fitness_scores)[-num_best:]\n",
    "        return [self.population[i] for i in best_indices]\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        \"\"\"Realiza cruce entre dos individuos para producir un nuevo conjunto de pesos.\"\"\"\n",
    "        child = []\n",
    "        for p1_layer, p2_layer in zip(parent1, parent2):\n",
    "            new_weights = [(p1 + p2) / 2 for p1, p2 in zip(p1_layer, p2_layer)]\n",
    "            child.append(new_weights)\n",
    "        return child\n",
    "\n",
    "    def mutate(self, weights):\n",
    "        \"\"\"Aplica mutación aleatoria a un conjunto de pesos.\"\"\"\n",
    "        for layer in weights:\n",
    "            for i in range(len(layer)):\n",
    "                if np.random.rand() < self.mutation_rate:\n",
    "                    layer[i] += np.random.normal()\n",
    "        return weights\n",
    "\n",
    "    def create_new_generation(self, best_individuals):\n",
    "        \"\"\"Crea una nueva generación usando los mejores individuos y aplicando cruce y mutación.\"\"\"\n",
    "        new_population = []\n",
    "        while len(new_population) < self.population_size:\n",
    "            parent1, parent2 = random.sample(best_individuals, 2)\n",
    "            child = self.crossover(parent1, parent2)\n",
    "            child = self.mutate(child)\n",
    "            new_population.append(child)\n",
    "        return new_population\n",
    "\n",
    "    def evolve(self):\n",
    "        \"\"\"Ejecuta el ciclo de evolución a través de varias generaciones.\"\"\"\n",
    "        for generation in range(self.num_generations):\n",
    "            print(f'Inciando generacion {generation}')\n",
    "\n",
    "            fitness_scores = []\n",
    "    \n",
    "                # Crea un ThreadPoolExecutor con tantos hilos como tamaño de la población\n",
    "            with ThreadPoolExecutor(max_workers=self.population_size) as executor:\n",
    "                # Define una lista de tareas para cada modelo en la población, asociada a su instancia de juego\n",
    "                futures = [\n",
    "                    executor.submit(self.evaluate_fitness, weight, generation, i)\n",
    "                    for i, weight in enumerate(self.population)\n",
    "                ]\n",
    "                \n",
    "                # Recolecta los resultados a medida que se completan las tareas\n",
    "                for future in as_completed(futures):\n",
    "                    fitness_scores.append(future.result())\n",
    "\n",
    "            print(f'Socres de la generacion {generation}: {fitness_scores}')\n",
    "            # Seleccionar los mejores individuos y generar la nueva población\n",
    "            best_individuals = self.select_best_individuals(fitness_scores, num_best=5)\n",
    "            self.population = self.create_new_generation(best_individuals)\n",
    "\n",
    "            print(f\"Generación {generation}: Mejor puntaje = {max(fitness_scores)}\")\n",
    "\n",
    "        # Obtener el mejor modelo entrenado\n",
    "        best_weights = self.select_best_individuals(fitness_scores, num_best=1)[0]\n",
    "        final_model = self.build_model()\n",
    "        for layer, weight in zip(final_model.layers, best_weights):\n",
    "            layer.set_weights(weight)\n",
    "\n",
    "        return final_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
